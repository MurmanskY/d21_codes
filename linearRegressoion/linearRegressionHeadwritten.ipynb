{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 9.293824\n",
      "w的估计误差: tensor([ 1.4350, -2.4247])\n",
      "b的估计误差: tensor([3.0977])\n",
      "epoch 2, loss 4.917643\n",
      "w的估计误差: tensor([ 1.0306, -1.7320])\n",
      "b的估计误差: tensor([2.2848])\n",
      "epoch 3, loss 2.605457\n",
      "w的估计误差: tensor([ 0.7397, -1.2369])\n",
      "b的估计误差: tensor([1.6852])\n",
      "epoch 4, loss 1.382695\n",
      "w的估计误差: tensor([ 0.5305, -0.8830])\n",
      "b的估计误差: tensor([1.2429])\n",
      "epoch 5, loss 0.735660\n",
      "w的估计误差: tensor([ 0.3801, -0.6303])\n",
      "b的估计误差: tensor([0.9168])\n",
      "epoch 6, loss 0.392787\n",
      "w的估计误差: tensor([ 0.2718, -0.4498])\n",
      "b的估计误差: tensor([0.6761])\n",
      "epoch 7, loss 0.211045\n",
      "w的估计误差: tensor([ 0.1939, -0.3209])\n",
      "b的估计误差: tensor([0.4986])\n",
      "epoch 8, loss 0.114562\n",
      "w的估计误差: tensor([ 0.1377, -0.2290])\n",
      "b的估计误差: tensor([0.3677])\n",
      "epoch 9, loss 0.063307\n",
      "w的估计误差: tensor([ 0.0973, -0.1634])\n",
      "b的估计误差: tensor([0.2710])\n",
      "epoch 10, loss 0.036058\n",
      "w的估计误差: tensor([ 0.0683, -0.1167])\n",
      "b的估计误差: tensor([0.1997])\n",
      "epoch 11, loss 0.021514\n",
      "w的估计误差: tensor([ 0.0474, -0.0834])\n",
      "b的估计误差: tensor([0.1468])\n",
      "epoch 12, loss 0.013767\n",
      "w的估计误差: tensor([ 0.0322, -0.0596])\n",
      "b的估计误差: tensor([0.1079])\n",
      "epoch 13, loss 0.009648\n",
      "w的估计误差: tensor([ 0.0214, -0.0428])\n",
      "b的估计误差: tensor([0.0792])\n",
      "epoch 14, loss 0.007436\n",
      "w的估计误差: tensor([ 0.0135, -0.0305])\n",
      "b的估计误差: tensor([0.0580])\n",
      "epoch 15, loss 0.006257\n",
      "w的估计误差: tensor([ 0.0078, -0.0218])\n",
      "b的估计误差: tensor([0.0423])\n",
      "epoch 16, loss 0.005625\n",
      "w的估计误差: tensor([ 0.0037, -0.0156])\n",
      "b的估计误差: tensor([0.0307])\n",
      "epoch 17, loss 0.005290\n",
      "w的估计误差: tensor([ 0.0009, -0.0112])\n",
      "b的估计误差: tensor([0.0222])\n",
      "epoch 18, loss 0.005111\n",
      "w的估计误差: tensor([-0.0012, -0.0081])\n",
      "b的估计误差: tensor([0.0159])\n",
      "epoch 19, loss 0.005016\n",
      "w的估计误差: tensor([-0.0028, -0.0060])\n",
      "b的估计误差: tensor([0.0112])\n",
      "epoch 20, loss 0.004965\n",
      "w的估计误差: tensor([-0.0040, -0.0044])\n",
      "b的估计误差: tensor([0.0079])\n",
      "epoch 21, loss 0.004937\n",
      "w的估计误差: tensor([-0.0047, -0.0034])\n",
      "b的估计误差: tensor([0.0053])\n",
      "epoch 22, loss 0.004922\n",
      "w的估计误差: tensor([-0.0052, -0.0026])\n",
      "b的估计误差: tensor([0.0034])\n",
      "epoch 23, loss 0.004914\n",
      "w的估计误差: tensor([-0.0056, -0.0020])\n",
      "b的估计误差: tensor([0.0020])\n",
      "epoch 24, loss 0.004910\n",
      "w的估计误差: tensor([-0.0060, -0.0016])\n",
      "b的估计误差: tensor([0.0011])\n",
      "epoch 25, loss 0.004907\n",
      "w的估计误差: tensor([-0.0061, -0.0013])\n",
      "b的估计误差: tensor([0.0003])\n",
      "epoch 26, loss 0.004906\n",
      "w的估计误差: tensor([-0.0062, -0.0013])\n",
      "b的估计误差: tensor([-0.0004])\n",
      "epoch 27, loss 0.004905\n",
      "w的估计误差: tensor([-0.0063, -0.0011])\n",
      "b的估计误差: tensor([-0.0009])\n",
      "epoch 28, loss 0.004905\n",
      "w的估计误差: tensor([-0.0064, -0.0009])\n",
      "b的估计误差: tensor([-0.0011])\n",
      "epoch 29, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0012])\n",
      "epoch 30, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0015])\n",
      "epoch 31, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0015])\n",
      "epoch 32, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 33, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 34, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 35, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 36, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 37, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 38, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 39, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0006])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 40, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 41, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 42, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 43, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 44, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 45, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 46, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 47, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 48, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 49, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 50, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 51, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 52, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 53, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 54, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 55, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0009])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 56, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0009])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 57, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 58, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 59, loss 0.004905\n",
      "w的估计误差: tensor([-0.0064, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 60, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0009])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 61, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 62, loss 0.004905\n",
      "w的估计误差: tensor([-0.0064, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 63, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 64, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0006])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 65, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0006])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 66, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0022])\n",
      "epoch 67, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 68, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 69, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0006])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 70, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 71, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 72, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 73, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 74, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 75, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 76, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 77, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 78, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 79, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 80, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 81, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 82, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0005])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 83, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0005])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 84, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0005])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 85, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0005])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 86, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 87, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 88, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 89, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 90, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 91, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 92, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 93, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 94, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0009])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 95, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 96, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 97, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 98, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 99, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 100, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 101, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 102, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 103, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 104, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 105, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 106, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 107, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 108, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 109, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 110, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 111, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 112, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0009])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 113, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 114, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 115, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 116, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 117, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 118, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 119, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0009])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 120, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 121, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 122, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 123, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 124, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 125, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 126, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 127, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0005])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 128, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 129, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 130, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 131, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 132, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 133, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 134, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 135, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 136, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 137, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 138, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 139, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0005])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 140, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0005])\n",
      "b的估计误差: tensor([-0.0021])\n",
      "epoch 141, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 142, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 143, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 144, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 145, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 146, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 147, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 148, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 149, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 150, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 151, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0005])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 152, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 153, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 154, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 155, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 156, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 157, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0006])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 158, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 159, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 160, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 161, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0005])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 162, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 163, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 164, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 165, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 166, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 167, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 168, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 169, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 170, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0010])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 171, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0009])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 172, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 173, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 174, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 175, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 176, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 177, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0009])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 178, loss 0.004904\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 179, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 180, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0007])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 181, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 182, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0006])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 183, loss 0.004905\n",
      "w的估计误差: tensor([-0.0069, -0.0006])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 184, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0006])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 185, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 186, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 187, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0017])\n",
      "epoch 188, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 189, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0009])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 190, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0009])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 191, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0010])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 192, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0012])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 193, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0011])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 194, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0010])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 195, loss 0.004905\n",
      "w的估计误差: tensor([-0.0066, -0.0009])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 196, loss 0.004905\n",
      "w的估计误差: tensor([-0.0065, -0.0008])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 197, loss 0.004904\n",
      "w的估计误差: tensor([-0.0067, -0.0008])\n",
      "b的估计误差: tensor([-0.0018])\n",
      "epoch 198, loss 0.004904\n",
      "w的估计误差: tensor([-0.0066, -0.0007])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "epoch 199, loss 0.004905\n",
      "w的估计误差: tensor([-0.0068, -0.0005])\n",
      "b的估计误差: tensor([-0.0020])\n",
      "epoch 200, loss 0.004905\n",
      "w的估计误差: tensor([-0.0067, -0.0005])\n",
      "b的估计误差: tensor([-0.0019])\n",
      "tensor([[ 2.0067],\n",
      "        [-3.3995]]) \n",
      " tensor([4.2019])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "手写实现线性回归模型\n",
    "\"\"\"\n",
    "import torch\n",
    "import random\n",
    "import matplotlib\n",
    "from d2l import torch as d2l  # 之前实现的函数包\n",
    "\n",
    "\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\"生成y = Xw + b + 噪声\n",
    "\n",
    "    Args:\n",
    "        w (tensor): 系数矩阵\n",
    "        b (tensor): 偏置项\n",
    "        num_examples (int): 样本数\n",
    "\n",
    "    Returns:\n",
    "        _type_: 特征向量, 标签\n",
    "    \"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b  # 注意matmul()函数的用法\n",
    "    y += torch.normal(0, 0.1, size=y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "def data_iter(batch_size, features, labels):\n",
    "    \"\"\"数据迭代器\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): 小批量的值\n",
    "        features (tensor): 特征值\n",
    "        labels (tensor): 标签\n",
    "\n",
    "    Yields:\n",
    "        _type_: 重复喂数据\n",
    "    \"\"\"\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))  # 获取所有下标\n",
    "    random.shuffle(indices)  # 对下标随机排序\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)]\n",
    "        )\n",
    "        yield features[batch_indices], labels[batch_indices]  # 迭代作用，一次喂一小部分，直到全部喂完\n",
    "\n",
    "def linreg(X, w, b):\n",
    "    \"\"\"线性回归模型\n",
    "\n",
    "    Args:\n",
    "        X (tensor): input data\n",
    "        w (tensor): hyperparameters\n",
    "        b (tensor): hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        tensor: Model calculation formula\n",
    "    \"\"\"\n",
    "    return torch.matmul(X, w) + b\n",
    "\n",
    "def squared_loss(y_hat, y):\n",
    "    \"\"\"均方损失\n",
    "\n",
    "    Args:\n",
    "        y_hat (tensor): predict value\n",
    "        y (tensor): true value\n",
    "\n",
    "    Returns:\n",
    "        float: mean squared loss\n",
    "    \"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n",
    "\n",
    "def sqd(params, lr, batch_size):\n",
    "    \"\"\"小批量梯度随机下降\n",
    "\n",
    "    Args:\n",
    "        params (tensor): hyperparameters\n",
    "        lr (float): hyperparameters learning rate\n",
    "        batch_size (int): 小批量大小\n",
    "    \"\"\"\n",
    "    with torch.no_grad(): #在上下文管理器内部，禁用自动梯度计算，提高性能，节省内存\n",
    "        for param in params: #遍历模型所有参数，\n",
    "            param -= lr * param.grad / batch_size # 使用平均梯度更新参数\n",
    "            param.grad.zero_()\n",
    "\n",
    "\n",
    "true_w = torch.tensor([2, -3.4]) \n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000) # 生成数据用的w和b，仍然是添加了一个噪声的\n",
    "# 最后的预测结果应该会和true_w和true_b相近\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "lr = 0.003\n",
    "num_epochs = 200\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)\n",
    "        l.sum().backward()\n",
    "        sqd([w, b], lr, batch_size)\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "        print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "        print(f'b的估计误差: {true_b - b}')\n",
    "print(w.detach(), '\\n', b.detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
